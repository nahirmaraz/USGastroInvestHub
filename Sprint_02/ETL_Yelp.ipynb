{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e419ac27",
   "metadata": {},
   "source": [
    "## ETL Preliminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "25f45444-897a-4a2a-a463-1cb904b1e8e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Using cached regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.66.1)\n",
      "Using cached regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2023.12.25\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "from google.cloud import storage\n",
    "import pyarrow.parquet as pq\n",
    "import pickle\n",
    "import io\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "nltk.download(\"vader_lexicon\")\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc3a0fb1-1239-4cfd-9b68-cccec430ccbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crea una instancia de cliente de GCS\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Especifica la ruta del archivo en GCS\n",
    "bucket_name = 'project_yelp_parquet'\n",
    "folder_name = 'Yelp'\n",
    "\n",
    "file_check_in = 'checkin.json'\n",
    "file_path_check_in = f'{folder_name}/{file_check_in}'\n",
    "\n",
    "file_tip = 'tip.json'\n",
    "file_path_tip = f'{folder_name}/{file_tip}'\n",
    "\n",
    "file_review = 'review.parquet'\n",
    "file_path_review = f'{folder_name}/{file_review}'\n",
    "\n",
    "file_user = 'user.parquet'\n",
    "file_path_user = f'{folder_name}/{file_user}'\n",
    "\n",
    "file_business = 'business.pkl'\n",
    "file_path_business = f'{folder_name}/{file_business}'\n",
    "\n",
    "file_metadata = 'metadata-sitios.parquet'\n",
    "file_path_metadata = f'gs://{bucket_name}/{file_metadata}'\n",
    "\n",
    "# Obtén el archivo JSON directamente desde GCS\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "blob_check_in = bucket.blob(file_path_check_in)\n",
    "blob_tip = bucket.blob(file_path_tip)\n",
    "blob_review = bucket.blob(file_path_review)\n",
    "blob_user = bucket.blob(file_path_user)\n",
    "blob_business = bucket.blob(file_path_business)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ea0c8f",
   "metadata": {},
   "source": [
    "# Business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "bc7e8cee-9378-48b0-8479-06e598389060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Carga el archivo pkl como un DataFrame usando pickle\n",
    "# Descargar el archivo pkl desde GCS como un flujo de bytes\n",
    "file_content_business = blob_business.download_as_bytes()\n",
    "df_business = pd.read_pickle(io.BytesIO(file_content_business))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b31641f8-b122-48fe-93ec-5ffe36179b58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'name', 'address', 'city', 'state', 'postal_code',\n",
       "       'latitude', 'longitude', 'stars', 'review_count', 'is_open',\n",
       "       'attributes', 'categories', 'hours', 'business_id', 'name', 'address',\n",
       "       'city', 'state', 'postal_code', 'latitude', 'longitude', 'stars',\n",
       "       'review_count', 'is_open', 'attributes', 'categories', 'hours'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ccbe698f-fa64-4580-8787-a1bdad984f01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear un contador para el sufijo\n",
    "suffix_counter = {}\n",
    "\n",
    "# Renombrar las columnas agregando sufijos\n",
    "new_columns = []\n",
    "for col in df_business.columns:\n",
    "    if col in suffix_counter:\n",
    "        # Columna duplicada: agregar sufijo '_duplicada'\n",
    "        new_col = col + '_duplicada'\n",
    "    else:\n",
    "        # Columna no duplicada: agregar sufijo '_1' y actualizar contador\n",
    "        suffix_counter[col] = 1\n",
    "        new_col = col + ''\n",
    "    new_columns.append(new_col)\n",
    "\n",
    "# Asignar los nuevos nombres de columna al DataFrame\n",
    "df_business.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9744f33a-eab6-4ea9-8244-dab7976b66fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtrar las columnas que contienen la palabra \"duplicada\" en su nombre\n",
    "columnas_a_eliminar = [col for col in df_business.columns if 'duplicada' in col]\n",
    "\n",
    "# Eliminar las columnas seleccionadas del DataFrame\n",
    "df_business = df_business.drop(columns=columnas_a_eliminar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c3e75b6f-b3b2-478d-8ede-2f232a58395d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'name', 'address', 'city', 'state', 'postal_code',\n",
       "       'latitude', 'longitude', 'stars', 'review_count', 'is_open',\n",
       "       'attributes', 'categories', 'hours'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "781bb1e7-69b8-46a5-aadc-e6cb89754231",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates_business = df_business.duplicated('business_id')\n",
    "print(duplicates_business.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4d60519f-00e1-4fd9-8941-653c5f1d31f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'CA' 'MO' 'AZ' 'PA' 'TN' 'FL' 'IN' 'LA' 'AB' 'NV' 'ID' 'DE' 'IL' 'NJ'\n",
      " 'NC' 'CO' 'WA' 'HI' 'UT' 'TX' 'MT' 'MI' 'SD' 'XMS' 'MA' 'VI' 'VT']\n"
     ]
    }
   ],
   "source": [
    "# Estados contenidos en 'state'\n",
    "print(df_business['state'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c96194db-42ca-4c8b-94be-61dca0f9b645",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtar registros de Florida\n",
    "df_business = df_business[df_business['state'].isin(['FL'])]\n",
    "print(df_business['state'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4ea6df9c-a462-4ffe-a69f-fd9b944c61bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id        0\n",
       "name               0\n",
       "address            0\n",
       "city               0\n",
       "state              0\n",
       "postal_code        0\n",
       "latitude           0\n",
       "longitude          0\n",
       "stars              0\n",
       "review_count       0\n",
       "is_open            0\n",
       "attributes      2446\n",
       "categories        18\n",
       "hours           4108\n",
       "dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "fd14eb6c-99bd-4ea4-8172-a31090a342db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reemplazar los valores nulos en la columna 'hours' con \"Categories not specified\"\n",
    "df_business['categories'].fillna('Categories not specified', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "586d9c90-953a-4110-aa2b-0db246b70aa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lista de palabras clave gatronomia\n",
    "gastronomia = ['Restaurant', 'Restaurants','Food','Bars','Bar','Café','Coffeehouse','Bistro','Tavern','Buffet','Brewpub','Pub','Brasserie','Specialty Coffee Shop','Pub','Churrería','Diner','Dining','Teahouse','Tea Room','Gas Station', 'Gas','Fuel Station','Fuel']\n",
    "\n",
    "# Filtrar los registros que contienen al menos una palabra clave en 'categories'\n",
    "df_business = df_business[df_business['categories'].str.contains('|'.join(gastronomia))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "42e85c99-e3c4-473f-a494-234e37f2e1e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear una lista de palabras clave de categorías de restaurantes étnicos\n",
    "comida_etnica = ['Chinese','Indian','Thai','Italian','Greek','Helthy','Helth','Latin','Mexican','Tacos','Burritos','Enchiladas','Argentinian','Peruvian','Ceviche','Lomo','Pisco','Colombian','Empanadas','Arepas','Asian','Japanese','Sushi','Ramen','Sashimi','Tempura','Korean','Kimchi','Vietnamese','African','Ethiopian','Nigerian','Middle Eastern','Lebanese','Hummus','Falafel','Shawarma','Tabbouleh','Israeli','Shakshuka','Falafel','Hummus','Iranian','Healthy','Vegetarian','Vegan','Gluten-free','Gluten-Free','Fresh','Seasonal','Casual']\n",
    "\n",
    "# Filtrar las filas donde la columna 'categories' contiene las palabras clave de restaurantes étnicos o 'Gas Stations'\n",
    "filtro_categorias = '|'.join(comida_etnica + ['Gas Stations'])\n",
    "df_business = df_business[df_business['categories'].str.contains(filtro_categorias, case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "46baf6bb-41d9-4325-98e0-0d82df4c02df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Food, Delis, Italian, Bakeries, Restaurants'\n",
      " 'Restaurants, Automotive, Delis, Gas Stations, Food, Coffee & Tea, Sandwiches, Convenience Stores'\n",
      " 'Cocktail Bars, Italian, Nightlife, Seafood, Bars, Restaurants' ...\n",
      " 'Restaurants, Japanese, Ramen'\n",
      " 'Convenience Stores, Gas Stations, Automotive, Food, Coffee & Tea'\n",
      " 'Mexican, Shaved Ice, Restaurants, Food, Food Stands']\n"
     ]
    }
   ],
   "source": [
    "# Listado de Categorias resultantes\n",
    "valores_unicos = df_business['categories'].unique()\n",
    "print(valores_unicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8d58087a-b303-4db3-82f2-60a761969839",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id       0\n",
       "name              0\n",
       "address           0\n",
       "city              0\n",
       "state             0\n",
       "postal_code       0\n",
       "latitude          0\n",
       "longitude         0\n",
       "stars             0\n",
       "review_count      0\n",
       "is_open           0\n",
       "attributes       62\n",
       "categories        0\n",
       "hours           511\n",
       "dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0809b15d-d1ac-4567-9d6a-8c28fa2af54f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3779, 14)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "87352a0f-5281-414b-9797-c34638136f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar los valores nulos en la columna 'hours' con \"Hours not specified\"\n",
    "df_business['hours'].fillna(\"Hours not specified\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b266134d-c455-4f2b-934f-86b61743160e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas a eliminar:\n",
      "is_open\n",
      "attributes\n"
     ]
    }
   ],
   "source": [
    "# Lista de columnas permitidas en el orden deseado\n",
    "columnas_permitidas = ['business_id', 'name', 'address', 'city', 'state', 'postal_code', 'latitude', 'longitude', 'stars', 'review_count', 'categories', 'hours']\n",
    "\n",
    "# Filtrar las columnas que se van a eliminar\n",
    "columnas_a_eliminar = [col for col in df_business.columns if col not in columnas_permitidas]\n",
    "\n",
    "# Imprimir las columnas que se eliminarán\n",
    "print(\"Columnas a eliminar:\")\n",
    "for col in columnas_a_eliminar:\n",
    "    print(col)\n",
    "\n",
    "# Filtrar las columnas permitidas\n",
    "df_business = df_business[columnas_permitidas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "90006a03-2e7c-4111-b872-5536f66f3b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3779 entries, 14 to 150283\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   business_id   3779 non-null   object\n",
      " 1   name          3779 non-null   object\n",
      " 2   address       3779 non-null   object\n",
      " 3   city          3779 non-null   object\n",
      " 4   state         3779 non-null   object\n",
      " 5   postal_code   3779 non-null   object\n",
      " 6   latitude      3779 non-null   object\n",
      " 7   longitude     3779 non-null   object\n",
      " 8   stars         3779 non-null   object\n",
      " 9   review_count  3779 non-null   object\n",
      " 10  categories    3779 non-null   object\n",
      " 11  hours         3779 non-null   object\n",
      "dtypes: object(12)\n",
      "memory usage: 383.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_business.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5ebc39c9-b27f-4bdd-9849-07d3f030f92c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0bPLkL0QhhPO5kt1_EXmNQ</td>\n",
       "      <td>Zio's Italian Market</td>\n",
       "      <td>2575 E Bay Dr</td>\n",
       "      <td>Largo</td>\n",
       "      <td>FL</td>\n",
       "      <td>33771</td>\n",
       "      <td>27.916116</td>\n",
       "      <td>-82.760461</td>\n",
       "      <td>4.5</td>\n",
       "      <td>100</td>\n",
       "      <td>Food, Delis, Italian, Bakeries, Restaurants</td>\n",
       "      <td>{'Monday': '10:0-18:0', 'Tuesday': '10:0-20:0'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               business_id                  name        address   city state  \\\n",
       "14  0bPLkL0QhhPO5kt1_EXmNQ  Zio's Italian Market  2575 E Bay Dr  Largo    FL   \n",
       "\n",
       "   postal_code   latitude  longitude stars review_count  \\\n",
       "14       33771  27.916116 -82.760461   4.5          100   \n",
       "\n",
       "                                     categories  \\\n",
       "14  Food, Delis, Italian, Bakeries, Restaurants   \n",
       "\n",
       "                                                hours  \n",
       "14  {'Monday': '10:0-18:0', 'Tuesday': '10:0-20:0'...  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "43fa9408-1803-4302-8112-06d07e47f29c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convertir el DataFrame a un archivo CSV en memoria\n",
    "csv_buffer = io.StringIO()\n",
    "df_business.to_csv(csv_buffer, index=False)\n",
    "csv_content = csv_buffer.getvalue().encode('utf-8')\n",
    "\n",
    "# Nombre del archivo en Google Cloud Storage\n",
    "blob_name = 'archivos_csv/datasets/procesados/df_business_procesado.csv'\n",
    "\n",
    "# Subir el archivo CSV al bucket\n",
    "blob = bucket.blob(blob_name)\n",
    "blob.upload_from_file(io.BytesIO(csv_content), content_type='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca281a10-e900-4586-9405-d87afe100511",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Check-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2d028393-259c-4f79-b405-fbcf525527cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al decodificar la línea: \n"
     ]
    }
   ],
   "source": [
    "# Lee el archivo JSON línea por línea y concatena los objetos JSON en una lista\n",
    "data_check_in = []\n",
    "for line in blob_check_in.download_as_text().split('\\n'):\n",
    "    try:\n",
    "        json_obj = json.loads(line)\n",
    "        data_check_in.append(json_obj)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error al decodificar la línea: {line}\")\n",
    "\n",
    "# Convierte los datos a un DataFrame de Pandas\n",
    "df_check_in = pd.DataFrame(data_check_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e28fc4a3-d5be-4d6d-933c-3974b6345ed2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'date'], dtype='object')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check_in.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "808cd9cc-d19d-4202-97d6-17a57b7dbcc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtrar df_check_in basado en los business_id de df_business\n",
    "df_check_in = df_check_in[df_check_in['business_id'].isin(df_business['business_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e63077a4-9715-4056-82b3-e9599d257b16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3718, 2)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5180d43e-17c8-4248-b88e-9ca6e53d34a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates_check_in = df_check_in.duplicated('business_id')\n",
    "print(duplicates_check_in.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1061c098-a2ea-41f0-ba86-29a6cbed06ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id    0\n",
       "date           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check_in.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9f13b2e1-685e-43fe-b298-c6adaa8973e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-03-13 21:10:56, 2020-06-02 22:18:06, 2020-07-24 22:42:27, 2020-10-24 21:36:13, 2020-12-09 21:23:33, 2021-01-20 17:34:57, 2021-04-30 21:02:03, 2021-05-25 21:16:54, 2021-08-06 21:08:08, 2021-10-02 15:15:42, 2021-11-11 16:23:50'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valor_date_checkin = df_check_in['date'].iloc[0]\n",
    "valor_date_checkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2f975de1-d884-4173-b979-bdc1e8f375b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Función para normalizar una fecha individual en una cadena con múltiples fechas\n",
    "def normalize_dates(date_str):\n",
    "    dates_list = date_str.split(\", \")\n",
    "    return [datetime.strptime(date, '%Y-%m-%d %H:%M:%S') for date in dates_list]\n",
    "\n",
    "# Normalizar la columna 'date' que contiene múltiples fechas en una sola cadena\n",
    "df_check_in['date'] = df_check_in['date'].apply(normalize_dates)\n",
    "\n",
    "# Explode la lista de fechas normalizadas en múltiples filas\n",
    "df_check_in = df_check_in.explode('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "33fc0728-ce2b-4ec6-bf22-164506679007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Renombrar la columna 'date' a 'date_and_hour'\n",
    "df_check_in.rename(columns={'date': 'date_and_hour'}, inplace=True)\n",
    "\n",
    "# Convertir la columna 'date_and_hour' a formato de cadena de texto\n",
    "df_check_in['date_and_hour'] = df_check_in['date_and_hour'].astype(str)\n",
    "\n",
    "# Dividir la columna 'date_and_hour' en dos nuevas columnas: 'date' y 'hour'\n",
    "df_check_in[['date', 'hour']] = df_check_in['date_and_hour'].str.split(' ', expand=True)\n",
    "\n",
    "# Convertir las columnas 'date' y 'hour' al formato datetime\n",
    "df_check_in['date'] = pd.to_datetime(df_check_in['date'])\n",
    "df_check_in['hour'] = pd.to_datetime(df_check_in['hour'], format='%H:%M:%S').dt.time\n",
    "\n",
    "# Eliminar la columna 'date_and_hour'\n",
    "df_check_in.drop(columns=['date_and_hour'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "91d2cca7-74b0-4fc1-9f30-8696dd87e56d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 599282 entries, 0 to 131910\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   business_id  599282 non-null  object        \n",
      " 1   date         599282 non-null  datetime64[ns]\n",
      " 2   hour         599282 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(2)\n",
      "memory usage: 18.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_check_in.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b976fcae-066d-402e-9142-1e7fccbe116e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>21:10:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>22:18:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>22:42:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n",
       "      <td>2020-10-24</td>\n",
       "      <td>21:36:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n",
       "      <td>2020-12-09</td>\n",
       "      <td>21:23:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n",
       "      <td>2021-01-20</td>\n",
       "      <td>17:34:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>21:02:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>21:16:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n",
       "      <td>2021-08-06</td>\n",
       "      <td>21:08:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n",
       "      <td>2021-10-02</td>\n",
       "      <td>15:15:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n",
       "      <td>2021-11-11</td>\n",
       "      <td>16:23:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0EdehHjIQc0DtYU8QcAig</td>\n",
       "      <td>2013-11-17</td>\n",
       "      <td>12:32:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               business_id       date      hour\n",
       "0   ---kPU91CF4Lq2-WlRu9Lw 2020-03-13  21:10:56\n",
       "1   ---kPU91CF4Lq2-WlRu9Lw 2020-06-02  22:18:06\n",
       "2   ---kPU91CF4Lq2-WlRu9Lw 2020-07-24  22:42:27\n",
       "3   ---kPU91CF4Lq2-WlRu9Lw 2020-10-24  21:36:13\n",
       "4   ---kPU91CF4Lq2-WlRu9Lw 2020-12-09  21:23:33\n",
       "5   ---kPU91CF4Lq2-WlRu9Lw 2021-01-20  17:34:57\n",
       "6   ---kPU91CF4Lq2-WlRu9Lw 2021-04-30  21:02:03\n",
       "7   ---kPU91CF4Lq2-WlRu9Lw 2021-05-25  21:16:54\n",
       "8   ---kPU91CF4Lq2-WlRu9Lw 2021-08-06  21:08:08\n",
       "9   ---kPU91CF4Lq2-WlRu9Lw 2021-10-02  15:15:42\n",
       "10  ---kPU91CF4Lq2-WlRu9Lw 2021-11-11  16:23:50\n",
       "11  -0EdehHjIQc0DtYU8QcAig 2013-11-17  12:32:05"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reiniciar el índice\n",
    "df_check_in = df_check_in.reset_index(drop=True)\n",
    "df_check_in.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "26a970db-6536-4908-9f00-f39223124170",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convertir el DataFrame df_check_in a un archivo CSV en memoria\n",
    "csv_buffer = io.StringIO()\n",
    "df_check_in.to_csv(csv_buffer, index=False)\n",
    "csv_content = csv_buffer.getvalue().encode('utf-8')\n",
    "\n",
    "# Nombre del archivo en Google Cloud Storage\n",
    "blob_name = 'archivos_csv/df_check_in.csv'\n",
    "\n",
    "# Subir el archivo CSV al bucket\n",
    "blob = bucket.blob(blob_name)\n",
    "blob.upload_from_file(io.BytesIO(csv_content), content_type='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30c1247-77b5-4ad6-8bd6-5e2c4204d08c",
   "metadata": {},
   "source": [
    "# Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6f7edff3-13af-484c-958a-02edb0c49b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lee los archivos Parquet de review y user desde GCS\n",
    "table_review = pq.read_table(blob_review.open('rb'))\n",
    "\n",
    "# Convierte los datos a DataFrames de Pandas (opcional)\n",
    "df_review = table_review.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "7680fb97-efe2-4f75-a7c1-230f6ea5385c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny',\n",
       "       'cool', 'text', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2fe45679-a2a0-4054-a88a-23b15e6acd34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtrar df_review basado en los business_id de df_business\n",
    "df_review = df_review[df_review['business_id'].isin(df_business['business_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "76e7263b-1371-4ad1-a427-0cad081f4b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352820, 9)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c5690c91-e887-42d4-9af5-1aa323f29aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id      0\n",
       "user_id        0\n",
       "business_id    0\n",
       "stars          0\n",
       "useful         0\n",
       "funny          0\n",
       "cool           0\n",
       "text           0\n",
       "date           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6aac302a-2c6e-4d8b-b133-6408a846ddf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Renombrar la columna 'date' a 'date_and_hour'\n",
    "df_review.rename(columns={'date': 'date_and_hour'}, inplace=True)\n",
    "\n",
    "# Convertir la columna 'date_and_hour' a formato de cadena de texto\n",
    "df_review['date_and_hour'] = df_review['date_and_hour'].astype(str)\n",
    "\n",
    "# Dividir la columna 'date_and_hour' en dos nuevas columnas: 'date' y 'hour'\n",
    "df_review[['date', 'hour']] = df_review['date_and_hour'].str.split(' ', expand=True)\n",
    "\n",
    "# Convertir las columnas 'date' y 'hour' al formato datetime\n",
    "df_review['date'] = pd.to_datetime(df_review['date'])\n",
    "df_review['hour'] = pd.to_datetime(df_review['hour'], format='%H:%M:%S').dt.time\n",
    "\n",
    "# Eliminar la columna 'date_and_hour'\n",
    "df_review.drop(columns=['date_and_hour'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "679fff45-c10b-48cb-ba10-4e293b8d0336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definir función para obtener la puntuación de sentimiento\n",
    "def get_sentiment_score(text):\n",
    "    if pd.isnull(text) or text == \"\":\n",
    "        return 1  # Valor neutral si el texto está vacío o es NaN\n",
    "    elif isinstance(text, str):\n",
    "        # Realizar análisis de sentimiento\n",
    "        sentiment = sia.polarity_scores(text)\n",
    "        compound_score = sentiment[\"compound\"]\n",
    "\n",
    "        # Escalar la puntuación entre 1 y 5\n",
    "        score = int(round(5 * compound_score))\n",
    "\n",
    "        # Asignar la puntuación\n",
    "        if score <= 2:\n",
    "            return 1\n",
    "        elif score <= 3:\n",
    "            return 2\n",
    "        elif score <= 4:\n",
    "            return 3\n",
    "        else:\n",
    "            return 4\n",
    "    else:\n",
    "        return 1  # Valor neutral para datos que no son de tipo cadena\n",
    "\n",
    "# Instanciar el modelo de análisis de sentimiento\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Asegurarse de que la columna 'text' sea de tipo cadena\n",
    "df_review[\"text\"] = df_review[\"text\"].astype(str)\n",
    "\n",
    "# Aplicar la función de análisis de sentimiento a la columna 'text' y crear una nueva columna 'sentiment_analysis'\n",
    "df_review[\"sentiment_analysis\"] = df_review[\"text\"].apply(get_sentiment_score)\n",
    "\n",
    "# Convertir la columna 'sentiment_analysis' al tipo de dato flotante si es necesario\n",
    "df_review[\"sentiment_analysis\"] = df_review[\"sentiment_analysis\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0398c393-7d50-4a2e-b505-ec8c9d3ba5c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas a eliminar:\n",
      "useful\n",
      "funny\n",
      "cool\n",
      "text\n"
     ]
    }
   ],
   "source": [
    "# Lista de columnas permitidas en el orden deseado\n",
    "columnas_permitidas = ['review_id', 'user_id', 'business_id', 'stars', 'date', 'hour', 'sentiment_analysis']\n",
    "\n",
    "# Filtrar las columnas que se van a eliminar\n",
    "columnas_a_eliminar = [col for col in df_review.columns if col not in columnas_permitidas]\n",
    "\n",
    "# Imprimir las columnas que se eliminarán\n",
    "print(\"Columnas a eliminar:\")\n",
    "for col in columnas_a_eliminar:\n",
    "    print(col)\n",
    "\n",
    "# Filtrar las columnas permitidas\n",
    "df_review = df_review[columnas_permitidas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "65b0f0b0-080b-4b43-845b-3cf10ff06683",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 352820 entries, 9 to 6990266\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   review_id           352820 non-null  object        \n",
      " 1   user_id             352820 non-null  object        \n",
      " 2   business_id         352820 non-null  object        \n",
      " 3   stars               352820 non-null  float64       \n",
      " 4   date                352820 non-null  datetime64[ns]\n",
      " 5   hour                352820 non-null  object        \n",
      " 6   sentiment_analysis  352820 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), object(4)\n",
      "memory usage: 21.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Verificar la información del DataFrame df_review\n",
    "df_review.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8c6c1442-9562-4317-8e9f-9ded8c5def21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pUycOfUwM8vqX7KjRRhUEA</td>\n",
       "      <td>59MxRhNVhU9MYndMkz0wtw</td>\n",
       "      <td>gebiRewfieSdtt17PTW6Zg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2016-07-25</td>\n",
       "      <td>07:31:06</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "9  pUycOfUwM8vqX7KjRRhUEA  59MxRhNVhU9MYndMkz0wtw  gebiRewfieSdtt17PTW6Zg   \n",
       "\n",
       "   stars       date      hour  sentiment_analysis  \n",
       "9    3.0 2016-07-25  07:31:06                 4.0  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "38873527-7a44-4499-928c-21d44bb4c99a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convertir el DataFrame df_review a un archivo CSV en memoria\n",
    "csv_buffer = io.StringIO()\n",
    "df_review.to_csv(csv_buffer, index=False)\n",
    "csv_content = csv_buffer.getvalue().encode('utf-8')\n",
    "\n",
    "# Nombre del archivo en Google Cloud Storage\n",
    "blob_name = 'archivos_csv/datasets/procesados/df_review_prosesado.csv'\n",
    "\n",
    "# Subir el archivo CSV al bucket\n",
    "blob = bucket.blob(blob_name)\n",
    "blob.upload_from_file(io.BytesIO(csv_content), content_type='text/csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
